spark：基于内存计算的大数据并行计算框架，采用DAG执行引擎；
spark还支持流式计算（spark streaming）、机器学习（MLlib）、图计算（GraphX）；
spark最大优势：将计算数据、中间结果都存储在内存中，大大减小了IO开销；
RDD（Resilient Distributed DataSet，弹性分布式数据集）：Spark中最基本的数据抽象；
每一个RDD包含的数据被存储在系统的不同节点上。逻辑上我们可以将RDD理解成一个大的数组，数组中的每个元素就代表一个分区(Partition)；
每个分区指向一个存储在内存或者硬盘中的数据块，这个数据块就是每个task计算出的数据块，它们可以分布在不同的节点上；
RDD不可变只读；
SparkContext：代表了与Spark节点的连接，可以创建RDD，一个线程只有一个SparkContext；
SparkConf：一些配置信息；
Partitioner：两种主流分区方式：1）Hash Partitioner；2）Range Partitioner；
Dependencies：窄依赖（父RDD分区可以一一对应找到子RDD的分区）、宽依赖（父RDD分区可以被子RDD多个分区使用）；
Storage Level：MEMORY_ONLY、MEMORY_AND_DISK、DISK_ONLY、MEMORY_ONLY_2、MEMORY_AND_DISK_2、DISK_ONLY_2（后缀2会建立副本）；
reduceByKey：相同的key执行特定操作，实例reduceByKey((x, k) => (x + y))或者reduceByKey()作用：key相同的value相加；
spark结构：
    1）一个应用（application） = 一个控制节点(Driver)+多个作业（Job）；
    2）一个作业 = 多个阶段（Stage）；
    3）一个阶段 = 多个任务（Task）；
    当执行一个应用时，Driver构建SparkContext，SparkContext会向集群管理器（监控+资源分配）申请运行Executor的资源，启动Executor，并向Executor发送应用程序
    代码和文件，然后在Executor上执行任务，运行结束后，执行结果会返回给Driver或者写入到HDFS或者其他数据库中；
spark.Executor：多线程实现，BlockingManager存储模块会将内存和磁盘共同作为存储设备，可存放中间结果进而减小IO；
spark.DAG调度器：SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAG调度器进行解析，将DAG图分解为多个stage并计算出各个stage之间的依赖关系，然后把stage提交给
底层的任务调度器进行处理；
Executor向SparkContext申请任务 = 任务调度器把任务分发给Executor + SparkContext将应用程序代码发放给Executor；
每个应用都有自己专属的Executor进程，Executor以多线程的方式运行；
造成数据倾斜的原因：groupBy、join（a表key数目100，b表key数目100，join之后新表key数目100*100）；
数据倾斜后果：某几台机器执行慢拖慢整个计算速度、甚至OOM；
数据倾斜解决方案：
    1）过滤异常key；
    2）提高shuffle并行度；
    3）自定义Partitioner（自定义数据分配规则）；
    4）key添加前缀，实现局部聚合+全局聚合；
spark在DAG调度中需要对计算过程划分Stage，而划分的依据就是就是RDD之间的依赖关系
依赖关系：
    1）窄依赖，父RDD的每一个分区只被子RDD的一个分区使用，一对一的关系，如map、filter操作；
    2）宽依赖，也称shuffle依赖，父RDD的每个分区都可能被多个子RDD分区使用，一个子RDD分区通常对应所有的父RDD分区，如groupByKey操作；
宽依赖需要将同一个父RDD的分区传入到不同的子RDD分区中，窄依赖只需要将一个父RDD的分区传入到一个子RDD分区中，所以如果发生RDD丢失，重新计算时，窄依赖只需要计算父分区RDD，极端情况下，宽依赖需要计算所有父分区RDD；
groupByKey和reduceByKey的区别：reduceByKey会先在本地做聚合，再移动，最后全局聚合，groupByKey少了第一步，因此reduceByKey效率更高；
跟hadoop一样，spark的分布式文件系统也是HDFS；
spark运行流程：
    1）构建Spark Application的运行环境，启动SparkContext；
    2）SparkContext向资源管理器（可以是Standalone、Mesos、Yarn）申请运行Executor资源，并启动StandaloneExecutorbackend；
    3）Executor向SparkContext申请Task；
    4）SparkContext将应用程序分发给Executor；
    5）SparkContext构建成DAG图，将DAG图分解成Stage、将Taskset发送给Task Scheduler，最后由Task Scheduler将Task发送给Executor运行；
    6）Task在Executor上运行，运行完释放所有资源；
SparkContext：运行在Driver，目的是为了准备Spark应用程序的运行环境，在Spark中有SparkContext负责与ClusterManager通信，
进行资源申请、任务的分配和监控等，当Executor部分运行完毕后，Driver同时负责将SparkContext关闭，通常用SparkContext代表Driver；
多个Task组成一个Stage，Task的调度和管理由TaskScheduler负责；
Job：包含多个Task组成的并行计算，往往由Spark Action触发生成，一个Application中往往会产生多个Job；
Stage: 每个Job会被拆分成多组Task，作为一个TaskSet，其名称为Stage，Stage的划分和调度是有DAGScheduler来负责的，
Stage有非最终的Stage（Shuffle Map Stage）和最终的Stage（Result Stage）两种，Stage的边界就是发生shuffle的地方；
DAG图是基于Stage的，DAGScheduler分配；
Job=多个stage，Stage=多个同种task, Task分为ShuffleMapTask和ResultTask，Dependency分为ShuffleDependency和NarrowDependency；
Cluter Manager：指的是在集群上获取资源的外部服务。目前有三种类型：
    1）Standalone : spark原生的资源管理，由Master负责资源的分配；
    2）Apache Mesos:与hadoop MR兼容性良好的一种资源调度框架；
    3）Hadoop Yarn: 主要是指Yarn中的ResourceManager；
RDD在Spark中运行大概分为以下三步：
    1）创建RDD对象；
    2）DAGScheduler模块介入运算，计算RDD之间的依赖关系，RDD之间的依赖关系就形成了DAG；
    3）每一个Job被分为多个Stage。划分Stage的一个主要依据是当前计算因子的输入是否是确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销；
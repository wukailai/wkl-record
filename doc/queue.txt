RabbitMQ：
    队列模型和发布-订阅模型最大的区别就是：一份消息数据能不能被消费多次；
    现代消息队列产品大多使用发布-订阅的消息模型，但RabbitMQ是个例外，依然坚持使用队列消息模型；

RabbitMQ：
    RabbitMQ解决多端消费的方式：Exchange位于生产者和队列之间，生产者直接将消息发送给Exchange，由Exchange上配置的策略决定将消息投递到哪个队列；
    几乎所有的消息队列产品都使用一种非常常用的“请求-确认”机制，确保消息不会在传递过程中因为网络或服务器故障而丢失；
    RocketMQ“请求-确认”机制：
        1）生产端生产者先将消息发送给服务端，也就是Broker，服务端在收到消息并将消息写入主题或队列后，会给生产者发送确认响应。如果生产者没有收到服务端的确认响应或者收到了失败的响应，则会重新发送消息；
        2）在消费端，消费者收到消息并完成自己的业务逻辑后，也会给服务端发送消费成功的确认消息，服务端只有收到消费确认后，才认为一条消息被成功消费，否则他会给消费者重新发送这条消息；
    RocketMQ确认机制带来的问题：为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消息的，否则就违背了消息的有序性原则，每个主题在任意时刻只能有一个消息者实例在进行消费，
    也就无法通过水平扩展消费者实例个数来提高消费端整体的消费性能，因此RocketMQ引入了队列的概念；
    RocketMQ队列：每个主题中包含多个队列，通过多个队列来实现并行的生产和消费（所以RocketMQ只能队列上保证消息的有序性，无法在主题上保证有序性）；
    RocketMQ订阅者的概念是通过消费组来体现的，每个消费组都消费主题中一份完整的数据，每个消费者负责消费组内的一部分消息，如果一条消息被某个消费者消费了，同一组内的其他消费者就不会再收到这条消息；
    RocketMQ上消费过的消息不会被立即删除，取而代之的是每个队列上维护一个消费位置（consumer offset，Talos叫commit offset），丢消息大多是消费位置处理不当造成的；

Kafka：
    概念同RocketMQ，只不过RocketMQ中的队列在kafka里面叫分区；
    offset可能是消费者批量处理后才提交到zk，重启后再消费时就可能会收到重复消息；
    生产消息阶段处理消息丢失方式：消息发送后，回调消息发送成功或者失败的接口。那么业务层面也就可以根据是否发送成功和失败做处理，
    比如发送前缓存到redis，发送成功后从redis中移除，对于在redis中一直没有处理的，再进行重发操作；
    消费消息阶段处理消息丢失方式：取消autoACK，业务逻辑处理完后手动ACK；
    解决消息积压的方式：修复consumer故障（如果有的话），新建topic，增加分区数量，消息写入新的topic，消费新topic的consumer的数量也应该增加；
    分区设置太大的弊端：延时增加；
    kafka保证数据可靠性：
        1）分区数据备份，数据同步；
        2）ISR：同步副本，和leader保持同步的follower动态集合（如果follower（主动从leader拉数据）长时间未向leader同步数据，踢出ISR，ISR也可以作为选举leader的候选集合）。当ISR中的follower完成数据的同步之后，leader就会给生产者发送ack；
        3）ACK机制：producer收到ack（ack=0：生产者消息发出去就算成功，ack=1：Leader ack，ack=all：leader+follower全部ack），就会进行下一轮的发送，否则重新发送数据；
    producer处理此类故障所采取的提交策略类型：
        1）at-least-once（重复的消息重试写入kafka）；
        2）at-most-once（不重试，消息丢失）；
        3）exactly-once（最理想，采用上面的redis方案）；
count(1)、count(字段)、count(*)的区别：count(1)、count(*)会算上null的记录，count(字段)不会算上null的记录；
执行效率：count(主键列) > count(1) > count(非主键列) = count(*)；
mysql优化小手段：
    1）使用exists、not exist代替in和not in；
    2）尽量不使用like语句；
    3）where条件中避免对字段进行函数操作；
    4）允许脏读可以预防查询被更新事务阻塞；
    5）尽量少用text，非用不可最好分表处理（单独放入一张表）；
    6）大语句拆小语句；
    7）使用同类型进行比较，比如用'123'和'123'比，123和123比；
    8）join代替子查询，因为子查询会创建临时表从而带来额外的开销；
    9）使用Explain和Describe分析sql语句执行信息；
    10）中间表、冗余字段从而减少连接查询；
    11）优化数据库参数；
    12）索引列有null值，is null走索引，is not null全表扫描；
    13）避免select *，减小网络开销；
    14）合理的字段类型；
    15）text单独抽出来；
    16）尽量设置not null；
    17）尽量使用TIMESTAMP（时区相关，会做时区转换）而非DATETIME（时区无关，或者说只支持当前时区）；
insert into table_a select * from table_b where condition > 1;隐患：table_a加表锁，table_b逐步锁（扫描一个锁一个，锁的数据越来越多）；
解决办法：条件判断字段condition加索引，避免全表扫描而锁表；
OLAP：仓库型数据库，主要是读取数据，做复杂的数据分析；
OLTP：传统的关系型数据库，强调事务一致性；
在where不满足条件的情况下，count(*)、sum(*)也有可能返回null；
limit可以较大提升性能；
linux连远端数据库（指定端口，非3306）指令：mysql -hip -Pport -uuser -ppassword；
mysql limit会让null最先显示；
limit起始位置越大，速度越慢，优化思路：选择自增id作为列，记录上一次limit位置，从这个位置开始下一次的limit读取；
select(*)效率低的原因：
    1）不需要的列会增加数据传输时间和网络开销（数据库列越多，消耗越大）；
    2）对于无用的大字段，如varchar、text，会增加io操作；
    3）失去”覆盖索引“策略优化的可能性；
    4）增加查询分析器解析成本；
覆盖索引直接读内存，而且不需要第二次查找；
联合索引(a,b,c)实际建立了(a)、(a,b)、(a,b,c)三个索引；
主键自增缺点：
    1）不安全；
    2）高并发场景下锁竞争；
顺序写比随机写要快400倍；
mysql redo日志：数据修改写入redo日志，这样即使宕机也可以快速恢复数据；
顺序访问要比随机访问（IO次数会多很多）要快很多；
not in：先计算子查询，再计算外查询，双层遍历做筛选；
exists：遍历外查询，每次遍历判断内表是否符合匹配条件，符合则加入返回集合中；
not in需要保证子查询的匹配字段都是非空的，否则会返回空集合；
not in对内外表都需要扫描，没有用到索引；
in适合外表大、内表小，exists适合外表小、内表大；
exists返回的是一个Boolean值，不关心返回的具体数据是什么；
select * from t1 where not exists (select name from t2 where t1.name=t2.name)可以优化为
select * from t1 where not exists (select 1 from t2 where t1.name=t2.name)，因为1>column>*；
select *会等价于查找所有字段；
对于exists来说，外表总是会执行全扫描，不会走索引，外表应该选小表；
不用null的原因：
    1）很难做查询优化；
    2）需占用额外的索引空间；
避免在where后面进行null值判断，否则会导致引擎放弃使用索引；
MyISAM支持全文索引，支持延迟更新索引，极大提升写入效率，InnoDB不支持全文索引；
mysql数据最终是保存在数据页中的，物理日志记录的就是数据页的变更；
WAL（Write-Ahead Logging）：先写日志，再写磁盘；
二进制日志：binlog
    1）记录数据库执行的写入性操作信息（就是sql语句），以追加的方式写入，以二进制的方式保存在磁盘中；
    2）使用场景：主从复制（master向slave发送binlog）、数据恢复；
    3）对于Innodb，只有事务提交时才会记录binlog；
事务日志：
    1）redo log；
        a）记录了事务对数据页做了哪些修改；
        b）分为两部分：内存中的日志缓冲和磁盘上的日志文件；
    2）undo log；
        a）记录了数据的逻辑变化，比如一条insert语句对应一条delete语句，回滚时使用；
SQL注入：传参当成执行语句一部分，如参数传' or '1'='1，这样name='${name}' <=> name='' or '1'='1'；
读未提交：写操作不加锁；读已提交：写操作加锁，且执行完写操作后立即释放锁；
可重复读：写操作加锁，且执行完事务后才释放锁；串行化：表锁，事务完成后释放锁；
行级锁：并发度高、但是加锁慢，开销大，有死锁风险，基于索引实现行锁；
页级锁：介于行级锁和表级锁之间，折中策略；
共享锁（读读不互斥）和排他锁
InnoDB存储引擎的锁的算法有三种
    1.Record lock：单个行记录上的锁
    2.Gap lock：间隙锁，锁定一个范围，不包括记录本身--阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
    3.Next-key lock：record+gap 锁定一个范围，包含记录本身
基础表、派生表（查询结果、临时表）、虚拟表（视图）；
turncate效率远高于delete，而且不走事务、不会锁表，也不会生产大量日志写入日志文件，立刻释放磁盘空间并重置auto_increment值；
delete会将所有涉及的行加写锁和Gap锁（where字段加了索引的情况下）；
加锁都是基于索引的，如果字段没有索引，就会扫描到主键索引上；
DELETE：假删除，仅仅给被删除数据打上已删除标记，因此磁盘存储空间不会被释放（除非使用optimize table table_name），下次插入数据时，可重用已删除空间；
TRUNCATE：不走事务；不触发trigger，立刻释放磁盘空间，执行后数据无法找回，等价于drop + create操作，会重置auto_increment；
drop：立即释放磁盘空间，执行后数据无法找回；
适合加索引的字段：where后面、order by后面（避免额外的排序）、group by后面（利用索引完成分组）、多表连接关联字段；
explain：查看是通过索引还是全局扫描，连接查询的实现方式和连接的顺序；
offset 大数字会严重影响查询性能；优化：记住上一次查询最大主键id，后续查询用where实现；
mysql隐式转换：比如字符串转int使用了函数，索引失效；
InnoDB使用日志先行策略（日志记录到数据库以后，对应的事务就可以返回给用户，表示事务完成。但是实际上，这个数据可能还只在内存中修改完，并没有刷到磁盘上去），
将数据修改先在内存中完成，并且将事务记录成重做日志(Redo Log，在系统崩溃时根据日志重建数据)，转换为顺序IO高效的提交事务；
检查点机制：即定期检查，保证检查点之前的日志都已经写到磁盘，则下次恢复只需要从检查点开始；
mysql mvcc依赖undo log实现；
设想一个场景：事务A开始事务，事务B也开始执行大量更新。B率先提交，A是当前读，就要依次执行undo log，直到找到事务B开始前的值；
binlog：insert（事务回滚时需要，事务提交后丢弃）、update、delete（事务回滚和快照读时需要，purge线程统一清除）产生；
索引失效原因：
    1）where使用!=或<>或or或表达式或函数；
    2）like语句%开头
    3）字符串未加""，引入了转换函数；
    4）索引区分度低，如性别；
    5）打破了最左前缀匹配规则；
    6）or操作，使用union优化；
binlog：记录所有数据库表结构变更（例如create、alter table）以及表数据修改(insert、update、delete)的二进制日志，主从同步用到的就是binlog；
    1）STATEMENT模式，只记录引起数据变更的sql语句，缺点：对uuid()等随机函数不友好；
    2）ROW模式，记录每次操作的源数据与修改后的目标数据，缺点是体积会非常大；
    3）MIXED模式，STATEMENT模式和ROW模式混合使用；
mysql主从同步实现：主节点必须启用二进制日志，从节点启动一个线程扮演mysql客户端，通过mysql协议请求主节点的二进制日志文件中的事件；
1、 记录更新时，InnoDB引擎就会先把记录写到RedoLog（粉板）里面，并更新内存。同时，InnoDB引擎会在空闲时将这个操作记录更新到磁盘里面。
2、 如果更新太多RedoLog处理不了的时候，需先将RedoLog部分数据写到磁盘，然后擦除RedoLog部分数据。RedoLog类似转盘。
RedoLog有write pos跟checkpoint，write pos和check point之间的是粉板上还空着的部分，可以用来记录新的操作；
1、prepare阶段 -->  2、写binlog  --> 3、commit；
redo log物理日志，记录的是在某个数据页上做了什么修改。binlog逻辑日志，记录的是这个语句的原始逻辑。redo log循环写，bin log追加写；
索引下推：可以在索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数；
页面锁：表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页面锁；
锁分类：
    1）lock in share mode 共享读锁，确保自己查到的数据没有被其他的事务正在修改，并且不允许其他人来修改数据；
    2）for update排它写锁，为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候；
    3）Gap Lock间隙锁，行锁只能锁住行，如果在记录之间的间隙插入数据就无法解决了，间隙锁是左右开区间；
    4）隙锁和行锁合称NextKeyLock，每个NextKeyLock是前开后闭区间；
mvcc：不加锁的条件下保证读写操作没有冲突；
当前读：像select lock in share mode(共享锁)、select for update 、update、insert、delete(排他锁)这些操作都是一种当前读，
就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁，悲观锁实现；
快照读：不加锁的select就是快照读；
undo log数据结构：链表；
一条sql执行过程：连接器->缓存->分析器（类似于编译器）->优化器->执行器->存储引擎；
select后面带for update表示排它锁；
行锁分类：
    1）普通行锁Record Lock，记录存在；
    2）间隙锁Gap Lock，记录不在加锁范围内，左右开区间；
    3）Next-Key Lock（等效于普通行锁+间隙锁，左闭右开区间），例子：数据库只有id=50的记录，select * from user where id > 49；
表锁（行锁失效才会变为表锁）分类：
    1）意向锁：事务A申请行锁之前数据库自动申请意向锁，后面申请表锁事务发现意向锁阻塞，不用判断表中的每一行是否已被行锁锁住；
    2）自增锁；
锁的分类：
    1）共享锁，读锁，防止其他事务拿改行数据的排他锁；
    2）排他锁，写锁，防止其他事务拿改行数据的排他锁和共享锁；
查看mysql数据库锁的效率：show status like "innodb_row_lock%";
explain查看索引是否命中：key + rows；
mysql8.0版本取消了查询缓存；
binlog三种模式：
    1）statement模式：记录引起数据变动的sql，优点是内存和IO消耗都很低，缺点是对随机函数（uuid()）不友好；
    2）row模式，记录每次操作的源数据与修改后的目标数据，优点精确还原，缺点是占内存；
    3）混合模式，statement和row模式的混合；
主从同步流程：
    1）从节点主动向主节点发出同步请求；
    2）从节点开启I/O线程，主节点开启dump线程；
    3）从节点同步请求如果不带请求位置参数，主节点从第一个日志文件（主节点二进制文件有多个）的第一个事件一个一个发送给从节点；
    4）从节点收到主节点发来的事件数据之后放入中继日志文件中，并记录请求到主节点哪一个二进制文件，文件里面哪一个位置；
    5）从节点开启sql线程从relay log读取事件并本地执行；
    6）主节点怎么判定同步成功：a）全同步复制：所有从库执行成功确认；b）半同步复制：至少一个从库执行成功确认；
Redo Log的思想：先写日志，再写磁盘（Write-Ahead Logging）；
Redo Log有write pos和checkpoint，两者之间的就是空着的部分，redo log循环写，binlog是追加写，redo log是物理日志，bin log是逻辑日志；
幻读只有在当前读才会触发（快照读不会看到别的事务插入的数据）；
mysql乐观锁通过版本号和时间戳实现；
MyISAM是一个支持读读并发，但不支持通用读写并发，写写并发的数据库引擎，所以它更适合用于读多写少的应用场合，一般工程中也用的较少；
lock in share modle共享读锁：确保自己查到的数据没有被其他的事务正在修改；
for update排它写锁：确保自己查到的数据是最新的数据，并且查到后的数据只允许自己来修改；
快照读的实现是基于多版本并发控制，因为当前读会加锁，既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本；
MVCC + 悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突；
MVCC + 乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突；
MVCC：行版本号 <= 当前事务 < 删除版本号（为null未指定也可以）；
explain查询结果分析：
    1、key（查看有没有使用索引） ；
    2、key_len（查看索引使用是否充分）；
    3、type（查看索引类型，为ref走了索引，all没有走索引） ；
    4、Extra（查看附加信息：排序、临时表、where条件为false等）；
流行的分库分表工具：Mycat和sharding-sphere；
mvcc read view：
    1、creator_trx_id:当前事务id；
    2、m_ids:所有事务的事务id；
    3、min_trx_id:m_ids里最小的事务id值；
    4、max_trx_id:m_ids里最大的事务id值；